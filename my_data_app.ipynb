{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "586fca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_50572/4055765181.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  f.write(\"\"\"\n"
     ]
    }
   ],
   "source": [
    "with open('my_data_app.py', 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# --- PAGE CONFIGURATION ---\n",
    "st.set_page_config(page_title=\"CoinAfrique Scraper\", layout=\"wide\")\n",
    "\n",
    "# --- APP HEADER & DESCRIPTION ---\n",
    "st.markdown(\"<h1 style='text-align: center; color: black;'>MY DATA APP - Coinafrique</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "st.markdown('''\n",
    "This app performs webscraping of data from Coinafrique across multiple pages.\n",
    "You can scrape with BeautifulSoup, download raw WebScraper exports, view a cleaned dashboard, and give feedback.\n",
    "* **Python libraries:** base64, pandas, streamlit, requests, bs4, sqlite3\n",
    "* **Data source:** https://sn.coinafrique.com\n",
    "''')\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def add_bg_from_local(image_file):\n",
    "    if os.path.exists(image_file):\n",
    "        with open(image_file, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read())\n",
    "        st.markdown(\n",
    "        f'''\n",
    "        <style>\n",
    "        .stApp {{\n",
    "            background-image: url(data:image/{\"jpg\"};base64,{encoded_string.decode()});\n",
    "            background-size: cover\n",
    "        }}\n",
    "        </style>\n",
    "        ''',\n",
    "        unsafe_allow_html=True\n",
    "        )\n",
    "\n",
    "def convert_df(df):\n",
    "    return df.to_csv(index=False).encode('utf-8')\n",
    "\n",
    "def load(dataframe, title, key, key1):\n",
    "    col1, col2, col3 = st.columns([1, 2, 1])\n",
    "    with col2:\n",
    "        if st.button(title, key=key1):\n",
    "            st.subheader(f\"{title}\")\n",
    "            st.write(f\"Dimensions: {dataframe.shape[0]} rows x {dataframe.shape[1]} columns\")\n",
    "            st.dataframe(dataframe.head(100)) \n",
    "            \n",
    "            csv = convert_df(dataframe)\n",
    "            st.download_button(\n",
    "                label=\"Download Full CSV\", \n",
    "                data=csv, \n",
    "                file_name=f'{title.replace(\" \", \"_\")}.csv', \n",
    "                mime='text/csv', \n",
    "                key=key\n",
    "            )\n",
    "\n",
    "def local_css(file_name):\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name) as f:\n",
    "            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)\n",
    "\n",
    "# --- OPTIMIZED DATA LOADER (CACHED) ---\n",
    "@st.cache_data\n",
    "def load_csv_data(filename):\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            return pd.read_csv(filename)\n",
    "        except Exception as e:\n",
    "            return pd.DataFrame()\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# --- OPTIMIZED DASHBOARD FUNCTION  ---\n",
    "def plot_category_stats_lite(df, category_name):\n",
    "    st.markdown(f\"### Analysis: {category_name}\")\n",
    "    \n",
    "    if df.empty:\n",
    "        st.warning(\"No data available.\")\n",
    "        return\n",
    "\n",
    "    # 1. SMART COLUMN DETECTION\n",
    "    price_col = next((c for c in df.columns if 'price' in c.lower() or 'prix' in c.lower()), None)\n",
    "    possible_addr = ['address', 'location', 'ville', 'lieu', 'adresse', 'region']\n",
    "    address_col = next((c for c in df.columns if c.lower().strip() in possible_addr), None)\n",
    "    possible_names = ['type_item', 'type_clothes', 'type_shoes', 'name', 'description', 'titre']\n",
    "    item_col = next((c for c in df.columns if c.lower().strip() in possible_names), df.columns[0])\n",
    "\n",
    "    # 2. FAST DATA CLEANING\n",
    "    if price_col:\n",
    "        df['clean_price'] = pd.to_numeric(\n",
    "            df[price_col].astype(str).str.replace(r'[^\\d]', '', regex=True), \n",
    "            errors='coerce'\n",
    "        )\n",
    "        df_clean = df.dropna(subset=['clean_price'])\n",
    "    else:\n",
    "        df_clean = df\n",
    "\n",
    "    # 3. METRICS\n",
    "    m1, m2, m3 = st.columns(3)\n",
    "    m1.metric(\"Total Items\", df.shape[0])\n",
    "    if price_col and not df_clean.empty:\n",
    "        m2.metric(\"Avg Price\", f\"{int(df_clean['clean_price'].mean()):,} CFA\")\n",
    "        m3.metric(\"Max Price\", f\"{int(df_clean['clean_price'].max()):,} CFA\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # 4. PLOTS\n",
    "    c1, c2 = st.columns(2)\n",
    "    with c1:\n",
    "        st.subheader(\"Top Locations\")\n",
    "        if address_col:\n",
    "            st.bar_chart(df[address_col].value_counts().head(10))\n",
    "        else:\n",
    "            st.info(f\"Address column not found.\")\n",
    "\n",
    "    with c2:\n",
    "        st.subheader(f\"Top Items ({item_col})\")\n",
    "        st.bar_chart(df[item_col].value_counts().head(10))\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # 5. PRICE DISTRIBUTION\n",
    "    st.subheader(\"Price Distribution\")\n",
    "    if price_col and not df_clean.empty:\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        ax.hist(df_clean['clean_price'], bins=30, color='skyblue', edgecolor='black')\n",
    "        ax.set_title(\"Price Range Distribution\")\n",
    "        ax.set_xlabel(\"Price (CFA)\")\n",
    "        ax.grid(axis='y', alpha=0.5)\n",
    "        st.pyplot(fig)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        st.info(\"No valid price data available for plotting.\")\n",
    "\n",
    "# --- SCRAPING FUNCTION ---\n",
    "def scrape_data(url_base, table_name, db_name, csv_name, user_pages, max_limit):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f'''CREATE TABLE IF NOT EXISTS {table_name} (type_item TEXT, price TEXT, address TEXT, image_link TEXT)''')\n",
    "    \n",
    "    actual_pages = min(user_pages, max_limit)\n",
    "    progress_text = f\"Scraping {table_name} (Target: {actual_pages} pages)...\"\n",
    "    my_bar = st.progress(0, text=progress_text)\n",
    "    \n",
    "    for index in range(1, actual_pages + 1):\n",
    "        try:\n",
    "            res = get(f'{url_base}?page={index}')\n",
    "            soup = bs(res.content, 'html.parser')\n",
    "            containers = soup.find_all('div', 'col s6 m4 l3')\n",
    "            for container in containers:\n",
    "                try:\n",
    "                    t = container.find('p', 'ad__card-description').text.strip()\n",
    "                    p = container.find('p', 'ad__card-price').text.replace('CFA', '').replace(' ', '')\n",
    "                    a = container.find('p', 'ad__card-location').span.text.strip()\n",
    "                    i = container.find('img', 'ad__card-img').get('src')\n",
    "                    c.execute(f'INSERT INTO {table_name} VALUES(?,?,?,?)', (t, p, a, i))\n",
    "                except: pass\n",
    "            conn.commit()\n",
    "        except: pass\n",
    "        my_bar.progress(index / actual_pages, text=f\"Scraping page {index}/{actual_pages}\")\n",
    "        \n",
    "    df = pd.read_sql_query(f'SELECT * FROM {table_name}', conn)\n",
    "    conn.close()\n",
    "    my_bar.empty()\n",
    "    \n",
    "    if not df.empty:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        df.to_csv(csv_name, index=False)\n",
    "    return df\n",
    "\n",
    "# --- FUNCTION: LOAD USER FILES ---\n",
    "def load_my_scraped_files():\n",
    "    st.markdown(\"<h3 style='text-align: center;'>My Local Scraped Files</h3>\", unsafe_allow_html=True)\n",
    "    files = [\n",
    "        (\"men_clothes.csv\", \"Men's Clothes\", \"k1\", \"b1\"), \n",
    "        (\"men_shoes.csv\", \"Men's Shoes\", \"k2\", \"b2\"),\n",
    "        (\"children_clothes.csv\", \"Children's Clothes\", \"k3\", \"b3\"),\n",
    "        (\"children_shoes.csv\", \"Children's Shoes\", \"k4\", \"b4\")\n",
    "    ]\n",
    "    \n",
    "    for filename, title, k, b in files:\n",
    "        df = load_csv_data(filename)\n",
    "        if not df.empty:\n",
    "            load(df, title, k, b)\n",
    "            st.write(\"---\")\n",
    "        else:\n",
    "            st.warning(f\"File '{filename}' not found in project folder.\")\n",
    "\n",
    "# --- MAIN APP LOGIC ---\n",
    "st.sidebar.header('User Input Features')\n",
    "\n",
    "# Slider capped at 120, but scraping logic limits children items to 22/8 automatically\n",
    "Pages = st.sidebar.slider('Pages to scrape', 1, 120, 1)\n",
    "\n",
    "Choices = st.sidebar.selectbox('Options', [\n",
    "    'Scrape data using beautifulSoup', \n",
    "    'Download scraped data', \n",
    "    'Load My Scraped Files', \n",
    "    'Dashbord of the data', \n",
    "    'Evaluate the App'\n",
    "])\n",
    "\n",
    "add_bg_from_local('img_file3.jpg') \n",
    "local_css('style.css')  \n",
    "\n",
    "# 1. SCRAPE\n",
    "if Choices == 'Scrape data using beautifulSoup':\n",
    "    st.info(f\"Scraping started. Max pages set to user input ({Pages}), capped by category limits.\")\n",
    "    \n",
    "    st.markdown(\"### 1. Men's Clothes\")\n",
    "    df_mc = scrape_data('https://sn.coinafrique.com/categorie/vetements-homme', \n",
    "                        'mens_clothes_tab', 'mens_clothes.db', 'mens_clothes_clean_data.csv', Pages, 119)\n",
    "    load(df_mc, 'Men Clothes Data', 'scr_dl_1', 'scr_btn_1')\n",
    "\n",
    "    st.markdown(\"### 2. Men's Shoes\")\n",
    "    df_ms = scrape_data('https://sn.coinafrique.com/categorie/chaussures-homme', \n",
    "                        'mens_shoes_tab', 'mens_shoes.db', 'mens_shoes_clean_data.csv', Pages, 119)\n",
    "    load(df_ms, 'Men Shoes Data', 'scr_dl_2', 'scr_btn_2')\n",
    "\n",
    "    st.markdown(\"### 3. Children's Clothes\")\n",
    "    df_cc = scrape_data('https://sn.coinafrique.com/categorie/vetements-enfants', \n",
    "                        'children_clothes_tab', 'children_clothes.db', 'children_clothes_clean_data.csv', Pages, 22)\n",
    "    load(df_cc, 'Children Clothes Data', 'scr_dl_3', 'scr_btn_3')\n",
    "\n",
    "    st.markdown(\"### 4. Children's Shoes\")\n",
    "    df_cs = scrape_data('https://sn.coinafrique.com/categorie/chaussures-enfants', \n",
    "                        'children_shoes_tab', 'children_shoes.db', 'children_shoes_clean_data.csv', Pages, 8)\n",
    "    load(df_cs, 'Children Shoes Data', 'scr_dl_4', 'scr_btn_4')\n",
    "\n",
    "# 2. DOWNLOAD SCRAPED\n",
    "elif Choices == 'Download scraped data': \n",
    "    st.header(\"Download Recently Scraped Data\")\n",
    "    files = [\n",
    "        ('mens_clothes_clean_data.csv', 'Mens Clothes Data', 'dl_1', 'btn_1'),\n",
    "        ('mens_shoes_clean_data.csv', 'Mens Shoes Data', 'dl_2', 'btn_2'),\n",
    "        ('children_clothes_clean_data.csv', 'Children Clothes Data', 'dl_3', 'btn_3'),\n",
    "        ('children_shoes_clean_data.csv', 'Children Shoes Data', 'dl_4', 'btn_4')\n",
    "    ]\n",
    "    for f, title, k, b in files:\n",
    "        df = load_csv_data(f)\n",
    "        if not df.empty:\n",
    "            load(df, title, k, b)\n",
    "            st.write(\"---\")\n",
    "        else:\n",
    "            st.warning(f\"File {f} not found. Please scrape data first.\")\n",
    "\n",
    "# 3. LOAD LOCAL FILES\n",
    "elif Choices == 'Load My Scraped Files':\n",
    "    load_my_scraped_files()\n",
    "\n",
    "# 4. DASHBOARD\n",
    "elif  Choices == 'Dashbord of the data': \n",
    "    st.header(\"Dashboard Analytics\")\n",
    "    tab1, tab2, tab3, tab4 = st.tabs([\"Men's Clothes\", \"Men's Shoes\", \"Kids Clothes\", \"Kids Shoes\"])\n",
    "    \n",
    "    files_map = {\n",
    "        \"Men's Clothes\": [\"men_clothes.csv\", \"mens_clothes_clean_data.csv\"],\n",
    "        \"Men's Shoes\": [\"men_shoes.csv\", \"mens_shoes_clean_data.csv\"],\n",
    "        \"Kids Clothes\": [\"children_clothes.csv\", \"children_clothes_clean_data.csv\"],\n",
    "        \"Kids Shoes\": [\"children_shoes.csv\", \"children_shoes_clean_data.csv\"]\n",
    "    }\n",
    "\n",
    "    def safe_plot(tab, name, filename_list):\n",
    "        with tab:\n",
    "            df = pd.DataFrame()\n",
    "            used_file = \"\"\n",
    "            for fname in filename_list:\n",
    "                if os.path.exists(fname):\n",
    "                    df = load_csv_data(fname)\n",
    "                    used_file = fname\n",
    "                    break\n",
    "            \n",
    "            if not df.empty:\n",
    "                st.caption(f\"Visualizing data from: {used_file}\")\n",
    "                plot_category_stats_lite(df, name)\n",
    "            else:\n",
    "                st.warning(f\"No data found for {name}. (Looked for: {', '.join(filename_list)})\")\n",
    "\n",
    "    safe_plot(tab1, \"Men's Clothes\", files_map[\"Men's Clothes\"])\n",
    "    safe_plot(tab2, \"Men's Shoes\", files_map[\"Men's Shoes\"])\n",
    "    safe_plot(tab3, \"Kids Clothes\", files_map[\"Kids Clothes\"])\n",
    "    safe_plot(tab4, \"Kids Shoes\", files_map[\"Kids Shoes\"])\n",
    "\n",
    "# 5. EVALUATE\n",
    "else:\n",
    "    st.markdown(\"<h3 style='text-align: center;'>Give your Feedback</h3>\", unsafe_allow_html=True)\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        st.link_button(\"Kobo Evaluation Form\", \"https://ee.kobotoolbox.org/x/yc2vAerV\")\n",
    "    with col2:\n",
    "        st.link_button(\"Google Forms Evaluation\", \"https://docs.google.com/forms/d/e/1FAIpQLSdgKBZpH9Lj6Ot0_4HT41gvD0yNpKSOjw3tOhih5uL5p5aWiQ/viewform?usp=header\")\n",
    "    \"\"\")\n",
    "    \n",
    "print(\"success !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065e9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
